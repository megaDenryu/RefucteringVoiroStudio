from api.Extend.BaseModel.model_dumpable import IModelDumpAble
from api.LLM.LLMAPIBase.LLMInterface.QueryProxy import QueryProxy, クエリ段落
from api.LLM.エージェント.会話用エージェント.自立型Ver1.体.BrainModule.脳内思考プロセス.記憶部署.I記憶部署 import I記憶部署
from api.LLM.エージェント.会話用エージェント.自立型Ver1.体.BrainModule.脳内思考プロセス.状況統合.状況オブジェクト import 状況履歴
from api.LLM.エージェント.会話用エージェント.自立型Ver1.体を持つ者.自分の情報.I自分の情報 import I自分の情報コンテナ


class 報酬ベクトル生成クエリプロキシ(QueryProxy):
    _クエリプロキシ: list[クエリ段落]
    def __init__(self) -> None:
        self._クエリプロキシ = []
    @classmethod
    def 履歴から生成(cls, v状況履歴: 状況履歴, v思考履歴: I記憶部署, vキャラクター情報:I自分の情報コンテナ) -> "報酬ベクトル生成クエリプロキシ":
        プロキシ = cls()
        プロキシ._クエリプロキシ = [
            クエリ段落("状況履歴", v状況履歴),
            クエリ段落("思考履歴", v思考履歴),
            クエリ段落("キャラクター情報", vキャラクター情報),
            クエリ段落("指示", プロキシ.指示文),
        ]
        return プロキシ
    
    @classmethod
    def 状況から報酬を生成(cls, 状況:list[IModelDumpAble|str]) -> "報酬ベクトル生成クエリプロキシ":
        プロキシ = cls()
        プロキシ._クエリプロキシ = []
        for index in range(len(状況)):
            状況要素 = 状況[index]
            プロキシ._クエリプロキシ.append(クエリ段落(f"状況{index}", 状況要素))
        プロキシ._クエリプロキシ.append(クエリ段落("指示", プロキシ.指示文))
        return プロキシ
    
    @classmethod
    def 未来予測から報酬を予測(cls, 未来予測:list[IModelDumpAble|str]) -> "報酬ベクトル生成クエリプロキシ":
        プロキシ = cls()
        プロキシ._クエリプロキシ = []
        for index in range(len(未来予測)):
            未来要素 = 未来予測[index]
            プロキシ._クエリプロキシ.append(クエリ段落(f"情報{index}", 未来要素))
        プロキシ._クエリプロキシ.append(クエリ段落("指示1", プロキシ.指示文))
        プロキシ._クエリプロキシ.append(クエリ段落("指示2", "この情報から、キャラクターが将来受け取れる報酬を予測してください。"))
        return プロキシ

    @property
    def 指示文(self) -> str:
        # 注意: このプロンプトは、LLMがBenefitモデルの構造（JSONスキーマ等で提示される想定）を
        # 理解していることを前提としています。
        return """
あなたは、キャラクターの行動や思考が、そのキャラクターの内面的な価値観や外面的な状況にどのような影響を与えるかを分析する役割を担います。
キャラクターは、精神エネルギー、肉体エネルギー、様々な側面からの自尊心・自信、他者からの評価、物理的リソースなどを「資産」として保持しています。（これは提示される `Benefit` モデルの構造に対応します）。
提示された「状況履歴」と「思考履歴」を詳細に分析してください。
そして、これらの出来事がキャラクターの「資産」にどのような**変化**をもたらしたか（あるいは、もたらすと予測されるか）を、**「報酬」ベクトル**として算出してください。
ここでの「報酬」ベクトルとは、キャラクターの「資産」ベクトルに対する**差分（変化量）**を意味します。以下の点を考慮して、指定されたJSONスキーマ（`Benefit` モデルに対応）に従って出力を生成してください。
- 各「資産」要素が増加した場合、対応する「報酬」要素は**正の値**になります。
- 各「資産」要素が減少した場合（コストが発生した場合など）、対応する「報酬」要素は**負の値**になります。
- 変化がない場合は**0**になります。
- 例えば、「他者に感謝された」状況では `ExternalRecognition` の `感謝` が増加（正の値）、「時間を浪費した」思考では `PhysicalCost` の `時間` が減少（負の値）すると考えられます。
- キャラクターの性格、価値観、目標（もし情報があれば）を考慮し、それぞれの「報酬」の大きさを判断してください。単なる出来事の有無だけでなく、キャラクターにとっての意味合いを重視してください。
"""